{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/bvs002/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import glob\n",
    "import json\n",
    "import pickle\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from collections import Counter\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from country_list import countries_for_language\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(module='sklearn*', action='ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.width', 100)\n",
    "pd.set_option('display.max_colwidth', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = 'labeled_npi.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.pkl from Kaggle notebook\n",
    "df = pd.read_pickle('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1612"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_apply(df, columns, n_comp):\n",
    "    new_df = df.copy()\n",
    "    for col in columns:\n",
    "        pca = PCA(n_components=n_comp, random_state=1)\n",
    "        new_df[col+'_pca'] = list(pca.fit_transform(np.stack(df[col].to_numpy())))\n",
    "    return new_df.reset_index(drop=True)\n",
    "\n",
    "def apply_scaler(df, columns):\n",
    "    new_df = df.copy()\n",
    "    for col in columns:\n",
    "        scaler = StandardScaler()\n",
    "        new_df[col + '_scaled'] = list(scaler.fit_transform(np.stack(df[col].to_numpy())))\n",
    "    return new_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocesser:\n",
    "    def __init__(self, df):\n",
    "        self.df_labels = pd.read_csv(DATA_FILE)\n",
    "        self.keywords = ['incident command system',\n",
    "                         'emergency operations',\n",
    "                         'joint information center',\n",
    "                         'social distancing',\n",
    "                         'childcare closers',\n",
    "                         'travel advisory',\n",
    "                         'travel warning',\n",
    "                         'isolation',\n",
    "                         'quarantine',\n",
    "                         'mass gathering cancellations',\n",
    "                         'school closures',\n",
    "                         'facility closures',\n",
    "                         'evacuation',\n",
    "                         'relocation',\n",
    "                         'restricting travel',\n",
    "                         'travel ban',\n",
    "                         'patient cohort',\n",
    "                         'npi']\n",
    "        self.occurances_minimum = 2\n",
    "        self.df_full = df\n",
    "        self.countries = set([k.lower() for k in dict(countries_for_language('en')).values()])\n",
    "        print(self.df_full.shape)\n",
    "        self.key_slice()\n",
    "        print(self.df_full.shape)\n",
    "\n",
    "    def run_process(self):\n",
    "        self.remove_punc(['body_text','abstract'])\n",
    "        self.remove_stopwords(['body_text', 'abstract'])\n",
    "        self.to_tfidf(['body_text', 'abstract'])\n",
    "        print('Running XG Boost Model')\n",
    "        self.npi_model()\n",
    "        print('Model Complete')\n",
    "        self.keyword_occurances_slice()\n",
    "        self.df_full = pca_apply(self.df_full, ['abstract_tfidf','body_text_tfidf'], 10)\n",
    "        self.df_full = apply_scaler(self.df_full,['abstract_tfidf_pca','body_text_tfidf_pca'])\n",
    "        print('NPI Slicing')\n",
    "        self.npi_slice()\n",
    "        self.set_country_columns()\n",
    "        print(self.df_full.shape)\n",
    "        \n",
    "    def set_country_columns(self):\n",
    "        def get_country(row):\n",
    "            text_set = set(row['body_text'].split(' '))\n",
    "            return list(self.countries.intersection(text_set))\n",
    "        self.df_full['countries'] = self.df_full.apply(get_country, axis=1)\n",
    "    \n",
    "    def key_slice(self):\n",
    "        self.df_full = self.df_full[self.df_full['abstract'].str.contains('|'.join(self.keywords), na=False, regex=True)].reset_index(drop=True)\n",
    "        \n",
    "    def keyword_occurances_slice(self):\n",
    "        def get_count(row):\n",
    "            return sum([row['abstract'].count(keyword) for keyword in self.keywords])\n",
    "        self.df_full = self.df_full[self.df_full.apply(get_count, axis=1) >= self.occurances_minimum]\n",
    "        \n",
    "    def remove_stopwords(self,columns):\n",
    "        stop = stopwords.words('english')\n",
    "        for col in columns:\n",
    "            self.df_full[col] = self.df_full[col].astype(str).apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "    def to_tfidf(self, columns):\n",
    "        for col in columns:\n",
    "            tfidfv = TfidfVectorizer()\n",
    "            self.df_full[col + '_tfidf'] = list(tfidfv.fit_transform(self.df_full[col]).toarray())\n",
    "            \n",
    "    def remove_punc(self, columns):\n",
    "        for col in columns:\n",
    "            self.df_full[col] = self.df_full[col].str.replace('[^a-zA-Z\\s]+','')\n",
    "            \n",
    "    def npi_model(self):\n",
    "        df = self.df_full.copy()\n",
    "        df = df.merge(self.df_labels, on=\"title\", how=\"inner\")\n",
    "        df = df.loc[df.isNPI.notna()]\n",
    "        pca_df = pca_apply(df, ['abstract_tfidf','body_text_tfidf'], 10)\n",
    "        scaled_df = apply_scaler(pca_df,['abstract_tfidf_pca','body_text_tfidf_pca'])\n",
    "        X = np.stack(scaled_df['body_text_tfidf_pca_scaled'].to_numpy())\n",
    "        y = scaled_df[\"isNPI\"]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10, stratify=y)\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic', 'eval_metric': 'auc'}\n",
    "        self.clf_xgb = xgb.XGBClassifier(max_depth=6, learning_rate=0.1,silent=False, objective='binary:logistic', \\\n",
    "                          booster='gbtree', n_jobs=8, nthread=None, gamma=0, min_child_weight=1, max_delta_step=0, \\\n",
    "                          subsample=0.8, colsample_bytree=0.8, colsample_bylevel=1, reg_alpha=0, reg_lambda=1)\n",
    "        self.clf_xgb.fit(X_train, y_train)\n",
    "        y_pred = self.clf_xgb.predict(X_test)\n",
    "        precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "        score = accuracy_score(y_test, y_pred)\n",
    "        print(f'Accuracy Score: {score}')\n",
    "        \n",
    "    def npi_slice(self):\n",
    "        def npi_col(row):\n",
    "            x = [row['body_text_tfidf_pca_scaled']]\n",
    "            y_pred = self.clf_xgb.predict(x)[0]\n",
    "            if y_pred > 0:\n",
    "                return True\n",
    "            return False\n",
    "        self.df_full['npi_pred'] = self.df_full.apply(npi_col, axis=1)\n",
    "        self.df_full = self.df_full[self.df_full['npi_pred']].reset_index(drop=True)\n",
    "        remove_list = ['body_text_tfidf',\n",
    "               'abstract_tfidf',\n",
    "               'abstract_tfidf_pca',\n",
    "               'body_text_tfidf_pca',\n",
    "               'npi_pred']\n",
    "        self.df_full = self.df_full.drop(columns=remove_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1612, 6)\n",
      "(1612, 6)\n"
     ]
    }
   ],
   "source": [
    "prepr = Preprocesser(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running XG Boost Model\n",
      "Accuracy Score: 0.8442622950819673\n",
      "Model Complete\n",
      "NPI Slicing\n",
      "(121, 9)\n"
     ]
    }
   ],
   "source": [
    "prepr.run_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df = prepr.df_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dimension(row):\n",
    "    return row[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df['abstract_tfidf_pca_scaled'] = cluster_df['abstract_tfidf_pca_scaled'].apply(reduce_dimension)\n",
    "cluster_df['body_text_tfidf_pca_scaled'] = cluster_df['body_text_tfidf_pca_scaled'].apply(reduce_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(row):\n",
    "    title_tokens = []\n",
    "    title = row['title']\n",
    "    if title == title:\n",
    "        title = re.sub('(/|\\|:|&|#|-|\\.)', '', title)\n",
    "        tokens = word_tokenize(title)\n",
    "        remove_sw = [word for word in tokens if word not in stopwords.words('english')]\n",
    "        remove_numbers = [word for word in remove_sw if not word.isnumeric()]\n",
    "        remove_comas = [word for word in remove_numbers if not word in [',', '(', ')', '\"', ':', '``', '.', '?']]\n",
    "        title_tokens.extend(remove_comas)\n",
    "    return [value[0] for value in Counter(title_tokens).most_common()[0:30]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_df['tokens'] = cluster_df.apply(tokenize, axis=1)\n",
    "cluster_df.to_pickle('final_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:8050/ (Press CTRL+C to quit)\n"
     ]
    }
   ],
   "source": [
    "# from dash.dependencies import Output, Input\n",
    "from dash.exceptions import PreventUpdate\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash\n",
    "import dash_html_components as html\n",
    "import dash_core_components as dcc\n",
    "import dash_bootstrap_components as dbc\n",
    "from dash.dependencies import Input, Output, State\n",
    "\n",
    "def get_breaks(row, col, word_limit=45, break_char='<br>', colon=True):\n",
    "    col_list = ['tokens', 'author_list', 'doi', 'countries']\n",
    "    if row[col] == row[col]:\n",
    "        data = ''\n",
    "        if col in col_list:\n",
    "            if col != 'tokens':\n",
    "                data = f'**{col.capitalize()}:** '\n",
    "            words = row[col]\n",
    "        elif colon:\n",
    "            if break_char == '<br>':\n",
    "                data = f'{col.capitalize()}: '\n",
    "            else:\n",
    "                data = f'**{col.capitalize()}:** '\n",
    "            words = row[col].split(' ')\n",
    "        else:\n",
    "            words = row[col].replace('<br>', '').split(' ')\n",
    "            words[0] = f'**{words[0]}**'\n",
    "        total_chars = 0\n",
    "\n",
    "        # add break every length characters\n",
    "        for i in range(len(words)):\n",
    "            total_chars += len(words[i])\n",
    "            if total_chars > word_limit:\n",
    "                data += f'{break_char}{words[i]}'\n",
    "                total_chars = 0\n",
    "            else:\n",
    "                if col in col_list and data:\n",
    "                    data += f' {words[i]},'\n",
    "                else:\n",
    "                    data += f' {words[i]}'\n",
    "        return data.strip().rstrip(',')\n",
    "    return row[col]\n",
    "\n",
    "def get_country_df(df):\n",
    "    country = []\n",
    "    count = []\n",
    "    for k in dict(countries_for_language('en')).values():\n",
    "        len_country = len(df[df['countries'].map(set([k.lower()]).issubset)])\n",
    "        country.append(k.lower())\n",
    "        count.append(len_country)\n",
    "    return pd.DataFrame({'country': country, 'count': count}) \n",
    "\n",
    "def get_wordcloud(df):\n",
    "    text = ''\n",
    "    for body_text in df['title']:\n",
    "        text = text + body_text\n",
    "    tokens = word_tokenize(text)\n",
    "    remove_sw = [word.lower() for word in tokens if word not in stopwords.words('english')]\n",
    "    remove_punct = [word for word in remove_sw if not word in [',', '(', ')', '\"', ':', '``', '.', '?', '<', '>', 'br', 'title']]\n",
    "    keywords = Counter(remove_punct).most_common()[0:5]\n",
    "    return ', '.join([keyword[0] for keyword in keywords])\n",
    "\n",
    "class Cluster_Plot:\n",
    "    def __init__(self, df, text_type, clust_nums):\n",
    "        self.cluster_id = 'all'\n",
    "        self.dimension = '3d'\n",
    "        self.styles = {\n",
    "            'pre': {\n",
    "                'border': 'thin lightgrey solid',\n",
    "                'overflowX': 'scroll'\n",
    "            }\n",
    "        }\n",
    "        self.search = ''\n",
    "        self.set_app()\n",
    "        self.df = df\n",
    "        self.set_text(text_type)\n",
    "        self.clust_nums = clust_nums\n",
    "        self.cluster_id_list = [{'label': i, 'value': i} for i in list(range(self.clust_nums))]\n",
    "        self.cluster_id_list.append({'label': 'all', 'value': 'all'})\n",
    "        self.create_cluster_df()\n",
    "        \n",
    "        if self.app is not None and hasattr(self, 'callbacks'):\n",
    "            self.callbacks(self.app)\n",
    "\n",
    "    def run_process(self):\n",
    "        self.set_app_layout()\n",
    "        self.app.config.suppress_callback_exceptions = True\n",
    "        self.app.run_server()\n",
    "        \n",
    "    def set_app(self):\n",
    "        self.app = dash.Dash(__name__,\n",
    "                        external_stylesheets=[dbc.themes.BOOTSTRAP, \"https://codepen.io/chriddyp/pen/bWLwgP.css\"])\n",
    "        \n",
    "    def set_app_layout(self):\n",
    "        self.app.layout = html.Div(children=[\n",
    "            html.Div(className='row', style={'background-color': '#142a57'}, children=[\n",
    "                html.Div(className='container', style={'max-width': 'unset'}, children=[\n",
    "                    html.Div(className='row', children=[\n",
    "                        html.Div(className='nine columns', children=[\n",
    "                            html.H1('NPI Cluster Analysis', style={ 'color': 'white', 'padding-top': '1%' })\n",
    "                        ])\n",
    "                    ])\n",
    "                ])\n",
    "            ]),\n",
    "            html.Div(className='container', style={'max-width': 'unset'}, children=[\n",
    "                html.Div(className='row', children=[\n",
    "                    html.Div(className='three columns', style={'padding-top': '5%'}, children=[\n",
    "                        dcc.Tabs(id=\"tabs\", value='tab-1', children=[\n",
    "                            dcc.Tab(label='Edit Clusters', value='tab-1'),\n",
    "                            dcc.Tab(label='Filter Articles', value='tab-2'),\n",
    "                        ])\n",
    "                    ]),\n",
    "                    html.Div(className='six columns', children=[\n",
    "                        html.Div(className='four columns', children=[\n",
    "                            dcc.Graph(id=\"geo-graph\", style={'height': '60px'})    \n",
    "                        ]),\n",
    "                        html.Div(className='eight columns', children=[\n",
    "                            html.Button(id='geo-button', style={'margin-left': '40%', 'margin-top': '20%'}, children='Reset Map')     \n",
    "                        ])\n",
    "                    ])\n",
    "                ]),\n",
    "                html.Div(className='row', style={'padding-top': '5%'}, children=[\n",
    "                    html.Div([\n",
    "                        dcc.Markdown(\"\"\"\n",
    "                            **Selected Article.**\n",
    "\n",
    "                            Click on values in the plot to select article.\n",
    "                        \"\"\"),\n",
    "                        dcc.Markdown(id='hover-data', style=self.styles['pre'])\n",
    "                    ], className='eight columns'),\n",
    "                    html.Div(className='four columns', style={\"float\": \"right\", 'left': '60%', 'top': '20px'}, children=[\n",
    "                        dcc.Graph(id=\"graph\", style={'width': '75%', 'height': '350px'}),\n",
    "                        html.H5('Current Cluser keywords'),\n",
    "                        html.Div(id='cluster_keywords'),\n",
    "                        html.Div(id='tabs-content')\n",
    "                    ])\n",
    "                ]),\n",
    "                html.Div(className='row', style={'margin-top': '10%'}, children=[\n",
    "                    html.Div(className='five columns', style={'display': 'none'}, children=[\n",
    "                         html.Div(id='dummy_dimension', style={'display':'none'}),\n",
    "                         html.Div(id='dummy_cluster_num', style={'display':'none'}),\n",
    "                         html.Div(id='dummy_text', style={'display':'none'}),\n",
    "                         html.Div(id='dummy_cluster_id', style={'display':'none'}),\n",
    "                         html.Div(id='dummy_search_string', style={'display':'none'}),\n",
    "                         html.Div(id='dummy_geo_graph', style={'display':'none'}),\n",
    "                         dcc.RadioItems(\n",
    "                                id='dimension',\n",
    "                                options=[{'label': ' 2d', 'value': '2d'},\n",
    "                                         {'label': ' 3d', 'value': '3d'}],\n",
    "                                value= self.dimension,\n",
    "                                style={'display': 'none'}\n",
    "                            ),\n",
    "                            dcc.RadioItems(\n",
    "                                id='abstract_or_body',\n",
    "                                options=[{'label': ' Abstract', 'value': 'abstract'},\n",
    "                                         {'label': ' Body', 'value': 'body_text'}],\n",
    "                                value=self.text_type,\n",
    "                                style={'display': 'none'}\n",
    "                            ),\n",
    "                            dcc.Dropdown(\n",
    "                                id='cluster_num',\n",
    "                                options=[{'label': i+1, 'value': i+1} for i in list(range(20))],\n",
    "                                value=self.clust_nums,\n",
    "                                style={'display': 'none'}\n",
    "                            ),\n",
    "                            dcc.Dropdown(\n",
    "                                id='cluster_id',\n",
    "                                options=self.cluster_id_list,\n",
    "                                value=self.cluster_id,\n",
    "                                style={'display': 'none'}\n",
    "                            ),\n",
    "                        dcc.Input(id='search',\n",
    "                                value='',\n",
    "                                type='text',\n",
    "                                style={'display': 'none'}\n",
    "                            )\n",
    "                    ])\n",
    "                ])\n",
    "            ])\n",
    "        ])\n",
    "        \n",
    "    def create_cluster_df(self):\n",
    "        new_df = self.df.copy()\n",
    "        kmeans = KMeans(n_clusters = self.clust_nums, random_state=1)\n",
    "        new_df[self.col_cluster_id] = list(kmeans.fit_predict(np.stack(new_df[self.col].to_numpy())))\n",
    "        self.cluster_df = new_df.reset_index(drop=True)\n",
    "        self.cluster_df['title'] = self.cluster_df.apply(get_breaks, args=('title',), axis=1)\n",
    "        self.cluster_df[['x', 'y', 'z']] = pd.DataFrame(self.cluster_df[self.col].values.tolist(),\n",
    "                                                        index = self.cluster_df.index)\n",
    "    \n",
    "    def set_text(self, text_type):\n",
    "        self.text_type = text_type\n",
    "        self.col = f'{self.text_type}_tfidf_pca_scaled'\n",
    "        self.col_cluster_id = f'{self.text_type}_tfidf_pca_scaled_clusterID'\n",
    "        \n",
    "    def callbacks(self, app):\n",
    "        @app.callback(Output('tabs-content', 'children'),\n",
    "              [Input('tabs', 'value')])\n",
    "        def render_content(tab):\n",
    "            articles_content = html.Div(className='filter-content', style={'background-color': 'white'}, children=[\n",
    "                            html.H4('Filter Articles'),\n",
    "                            html.Label('Search keywords'),\n",
    "                            dcc.Input(id='search',\n",
    "                                value='',\n",
    "                                type='text'\n",
    "                            ),\n",
    "                            html.Button(id='submitBtn', children='submit')\n",
    "                        ])\n",
    "            cluster_content = html.Div(id='cluster-content', style={'width': '100%', 'background-color': 'white'}, children=[\n",
    "                            html.H4('Cluster Control Panel'),\n",
    "                            html.Label('Select to show 2d or 3d visualization'),\n",
    "                            dcc.RadioItems(\n",
    "                                id='dimension',\n",
    "                                options=[{'label': ' 2d', 'value': '2d'},\n",
    "                                         {'label': ' 3d', 'value': '3d'}],\n",
    "                                value='3d'\n",
    "                            ),\n",
    "                            html.Label('Select to cluster on the article abstract or body'),\n",
    "                            dcc.RadioItems(\n",
    "                                id='abstract_or_body',\n",
    "                                options=[{'label': ' Abstract', 'value': 'abstract'},\n",
    "                                         {'label': ' Body', 'value': 'body_text'}],\n",
    "                                value=self.text_type\n",
    "                            ),\n",
    "                            html.Label('Select number of Clusters'),\n",
    "                            dcc.Dropdown(\n",
    "                                id='cluster_num',\n",
    "                                options=[{'label': i+1, 'value': i+1} for i in list(range(20))],\n",
    "                                value=self.clust_nums\n",
    "                            ),\n",
    "                            html.Label('Select cluster to view'),\n",
    "                            dcc.Dropdown(\n",
    "                                id='cluster_id',\n",
    "                                options=self.cluster_id_list,\n",
    "                                value='all'\n",
    "                            )\n",
    "                        ])\n",
    "            if tab == 'tab-1':\n",
    "                return cluster_content\n",
    "            elif tab == 'tab-2':\n",
    "                return articles_content\n",
    "         \n",
    "        \n",
    "        @app.callback([Output('cluster_id', 'options'),\n",
    "                       Output('dummy_cluster_num', 'children')],\n",
    "                      [Input('cluster_num', 'value')])\n",
    "        def set_cluster_options(cluster_num):\n",
    "            self.clust_nums = cluster_num\n",
    "            self.cluster_id_list = [{'label': i, 'value': i} for i in list(range(self.clust_nums))]\n",
    "            self.cluster_id_list.append({'label': 'all', 'value': 'all'})\n",
    "            return self.cluster_id_list, ''\n",
    "        \n",
    "        @app.callback(Output('dummy_dimension', 'children'),\n",
    "                      [Input('dimension', 'value')])\n",
    "        def set_dimension(dimension):\n",
    "            self.dimension = dimension\n",
    "\n",
    "        @app.callback(Output('dummy_cluster_id', 'children'),\n",
    "                      [Input('cluster_id', 'value')])\n",
    "        def set_cluster_id(cluster_id):\n",
    "            self.cluster_id = cluster_id\n",
    "            \n",
    "        @app.callback(Output('dummy_text', 'children'),\n",
    "                      [Input('abstract_or_body', 'value')])\n",
    "        def set_abstract_or_body(abstract_or_body):\n",
    "            self.set_text(abstract_or_body)\n",
    "            \n",
    "        @app.callback(Output('dummy_search_string', 'children'),\n",
    "                      [Input('submitBtn', 'n_clicks')],\n",
    "                      [State('search', 'value')])\n",
    "        def set_search(clicks, search):\n",
    "            self.search = search\n",
    "            \n",
    "        @app.callback(Output('dummy_geo_graph', 'children'),\n",
    "                      [Input('geo-graph', 'clickData'),\n",
    "                       Input('geo-button', 'n_clicks')])\n",
    "        def set_geo_graph(geo_click_data, clicks):\n",
    "            changed_id = [p['prop_id'] for p in dash.callback_context.triggered][0]\n",
    "            if 'geo-button' not in changed_id:\n",
    "                self.geo_click_data = geo_click_data\n",
    "            else:\n",
    "                self.geo_click_data = ''\n",
    "        \n",
    "        @app.callback([Output('graph', 'figure'), Output('geo-graph', 'figure'), Output('cluster_keywords', 'children')],\n",
    "                      [Input('dummy_dimension', 'children'),\n",
    "                       Input('dummy_cluster_num', 'children'),\n",
    "                       Input('dummy_cluster_id', 'children'),\n",
    "                       Input('dummy_text', 'children'),\n",
    "                       Input('dummy_search_string', 'children'),\n",
    "                       Input('dummy_geo_graph', 'children')\n",
    "                       ])\n",
    "        def update_clusters(dummy1, dummy2, dummy3, dummy4, dummy5, dummy6):\n",
    "            self.create_cluster_df()\n",
    "            df = self.cluster_df.copy()\n",
    "            show_scale = True\n",
    "            cluster_keywords = None\n",
    "            if self.cluster_id != 'all':\n",
    "                show_scale = False\n",
    "                df = df[df[self.col_cluster_id] == self.cluster_id]\n",
    "                cluster_keywords = get_wordcloud(df)\n",
    "            if self.geo_click_data:\n",
    "                country = self.geo_click_data['points'][0]['location']\n",
    "                if len(df[df['countries'].map(set([country]).issubset)]):\n",
    "                    df = df[df['countries'].map(set([country]).issubset)]\n",
    "            if self.search:\n",
    "                if len(df[df['tokens'].map(set([self.search]).issubset)]):\n",
    "                    df = df[df['tokens'].map(set([self.search]).issubset)]\n",
    "            country_df = get_country_df(df)\n",
    "            if self.dimension == '2d':\n",
    "                fig = px.scatter(df, x='x', y='y',\n",
    "                                 color=self.col_cluster_id,\n",
    "                                 hover_name='title',\n",
    "                                 hover_data=['paper_id', 'doi'])\n",
    "                fig.update_layout(title = '2D cluster of research papers',\n",
    "                                  xaxis = dict(dtick=1, range=[-5,5], scaleratio = 1),\n",
    "                                  yaxis = dict(dtick=1, range=[-5,5], scaleratio = 1),\n",
    "                                  hoverlabel=dict(\n",
    "                                    bgcolor='white', \n",
    "                                    font_size=8, \n",
    "                                    font_family='Rockwell'\n",
    "                                  ),\n",
    "                                  coloraxis=dict(\n",
    "                                    colorbar=dict(title='Cluster ID'),\n",
    "                                    showscale=show_scale\n",
    "                                  ))\n",
    "            elif self.dimension == '3d':\n",
    "                fig = px.scatter_3d(df, x='x', y='y', z='z',\n",
    "                                    color=self.col_cluster_id,\n",
    "                                    hover_name='title',\n",
    "                                    hover_data=['paper_id', 'doi'])\n",
    "                fig.update_layout(title = '3D cluster of research papers',\n",
    "                                  paper_bgcolor='rgba(0,0,0,0)',\n",
    "                                  scene = dict(\n",
    "                                    xaxis = dict(dtick=1, range=[-5,5],),\n",
    "                                    yaxis = dict(dtick=1, range=[-5,5],),\n",
    "                                    zaxis = dict(dtick=1, range=[-5,5],),),\n",
    "                                  hoverlabel=dict(\n",
    "                                    bgcolor='white', \n",
    "                                    font_size=8, \n",
    "                                    font_family='Rockwell'\n",
    "                                  ),\n",
    "                                  coloraxis=dict(\n",
    "                                    colorbar=dict(title='Cluster ID'),\n",
    "                                    showscale=show_scale\n",
    "                                  ))\n",
    "            fig2 = px.scatter_geo(country_df,\n",
    "                                  locationmode='country names',\n",
    "                                  locations='country',\n",
    "                                  hover_name='country',\n",
    "                                  size='count',\n",
    "                                  projection='natural earth')\n",
    "            fig2.update_layout(autosize=False,\n",
    "                               width=500,\n",
    "                               height=250,\n",
    "                               paper_bgcolor='rgba(0,0,0,0)'\n",
    "                              )\n",
    "            self.search = ''\n",
    "            return fig, fig2, cluster_keywords\n",
    "        \n",
    "        @app.callback(Output(\"hover-data\", \"children\"),\n",
    "                      [Input(\"graph\", \"clickData\")])\n",
    "        def display_click_data(clickData):\n",
    "            string = None\n",
    "            if clickData:\n",
    "                click_paper_id = clickData['points'][0]['customdata'][0]\n",
    "                click_index = self.cluster_df[self.cluster_df['paper_id'] == click_paper_id].index[0]\n",
    "                token_string = ''\n",
    "                country_string = ''\n",
    "                if self.cluster_df.iloc[click_index][\"tokens\"]:\n",
    "                    token_string = get_breaks(self.cluster_df.iloc[click_index],\n",
    "                                              'tokens',\n",
    "                                              word_limit=100,\n",
    "                                              break_char='\\n')\n",
    "                    token_string = f'**Keywords**: {token_string}'\n",
    "                if self.cluster_df.iloc[click_index][\"countries\"]:\n",
    "                    country_string = get_breaks(self.cluster_df.iloc[click_index],\n",
    "                                                'countries',\n",
    "                                                word_limit=100,\n",
    "                                                break_char='\\n')\n",
    "                    \n",
    "                string = get_breaks(self.cluster_df.iloc[click_index],\n",
    "                                    'title',\n",
    "                                    word_limit=100,\n",
    "                                    break_char='\\n',\n",
    "                                    colon=False)\n",
    "                item_list = ['abstract', 'body_text', 'author_list', 'paper_id', 'doi']\n",
    "                for i in item_list:\n",
    "                    formatted_data = get_breaks(self.cluster_df.iloc[click_index],\n",
    "                                                i,\n",
    "                                                word_limit=100,\n",
    "                                                break_char='\\n')\n",
    "                    string += f'\\n\\n{formatted_data}'\n",
    "                if token_string:\n",
    "                    string = f'{token_string}\\n\\n{string}'\n",
    "                if country_string:\n",
    "                    string = f'{country_string}\\n\\n{string}'\n",
    "                return string\n",
    "            return string\n",
    "\n",
    "c = Cluster_Plot(cluster_df, 'abstract', 10)\n",
    "c.run_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
